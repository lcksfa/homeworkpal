#!/usr/bin/env python3
"""
è¯­æ–‡æ•™æRAGæœç´¢æµ‹è¯•
Chinese Textbook RAG Search Test

æµ‹è¯•è¯­æ–‡æ•™æçš„æ™ºèƒ½æ£€ç´¢å’Œé—®ç­”åŠŸèƒ½
"""

import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from dotenv import load_dotenv
load_dotenv()

from homeworkpal.database.connection import engine
from sqlalchemy.orm import sessionmaker
from homeworkpal.database.models import TextbookChunk
import numpy as np
import json

def print_status(message: str, status: str):
    """æ‰“å°çŠ¶æ€ä¿¡æ¯"""
    icons = {"âœ…": "âœ…", "âŒ": "âŒ", "âš ï¸": "âš ï¸", "ğŸ”§": "ğŸ”§", "ğŸ“š": "ğŸ“š", "ğŸ”": "ğŸ”", "ğŸ’¾": "ğŸ’¾", "ğŸ“–": "ğŸ“–"}
    print(f"{icons.get(status, 'â„¹ï¸')} {message}")


def test_chinese_textbook_search():
    """æµ‹è¯•è¯­æ–‡æ•™ææœç´¢åŠŸèƒ½"""
    print_status("æµ‹è¯•è¯­æ–‡æ•™æå†…å®¹æœç´¢", "ğŸ”")

    try:
        SessionLocal = sessionmaker(bind=engine)
        session = SessionLocal()

        # æµ‹è¯•æŸ¥è¯¢åˆ—è¡¨
        test_queries = [
            "èŠ±çš„å­¦æ ¡ æ³°æˆˆå°”",
            "å­™ä¸­å±± ä¸æ‡‚å°±è¦é—®",
            "å¤è¯—ä¸‰é¦– å±±è¡Œ",
            "ç§‹å¤©çš„é›¨",
            "å¤§é’æ ‘ä¸‹çš„å°å­¦",
            "å£è¯­äº¤é™…",
            "è¯­æ–‡å›­åœ°",
            "ä¹ ä½œ çŒœçŒœä»–æ˜¯è°"
        ]

        for query in test_queries:
            print(f"\nğŸ” æœç´¢æŸ¥è¯¢: {query}")
            print("-" * 50)

            # è·å–æ‰€æœ‰çŸ¥è¯†ç‰‡æ®µ
            chunks = session.query(TextbookChunk).all()

            # å…³é”®è¯åŒ¹é…æœç´¢
            relevant_chunks = []
            query_keywords = query.split()

            for chunk in chunks:
                content_lower = chunk.content.lower()
                metadata = chunk.metadata_json or {}

                # è®¡ç®—ç›¸å…³æ€§å¾—åˆ†
                relevance_score = 0
                for keyword in query_keywords:
                    keyword_lower = keyword.lower()
                    if keyword_lower in content_lower:
                        relevance_score += 1
                    # æ£€æŸ¥å…ƒæ•°æ®
                    if metadata.get('lesson_title') and keyword_lower in metadata['lesson_title'].lower():
                        relevance_score += 2  # è¯¾æ–‡æ ‡é¢˜åŒ¹é…æƒé‡æ›´é«˜
                    if metadata.get('unit_title') and keyword_lower in metadata['unit_title'].lower():
                        relevance_score += 1.5  # å•å…ƒæ ‡é¢˜åŒ¹é…

                if relevance_score > 0:
                    relevant_chunks.append((chunk, relevance_score))

            # æŒ‰ç›¸å…³æ€§æ’åº
            relevant_chunks.sort(key=lambda x: x[1], reverse=True)

            if relevant_chunks:
                print(f"ğŸ“Š æ‰¾åˆ° {len(relevant_chunks)} ä¸ªç›¸å…³ç‰‡æ®µ")
                for i, (chunk, score) in enumerate(relevant_chunks[:3]):  # æ˜¾ç¤ºå‰3ä¸ªæœ€ç›¸å…³çš„
                    print(f"\n--- ç›¸å…³ç‰‡æ®µ {i+1} (ç›¸å…³åº¦: {score:.1f}) ---")
                    metadata = chunk.metadata_json or {}
                    print(f"ğŸ“– è¯¾æ–‡: {metadata.get('lesson_title', 'æœªçŸ¥')}")
                    print(f"ğŸ“š å•å…ƒ: {metadata.get('unit_title', 'æœªçŸ¥')}")
                    print(f"ğŸ“„ é¡µç : {chunk.page_number}")
                    print(f"â­ è´¨é‡è¯„åˆ†: {chunk.quality_score:.3f}")
                    print(f"ğŸ“ å†…å®¹é¢„è§ˆ: {chunk.content[:150]}...")
            else:
                print("âŒ æœªæ‰¾åˆ°ç›¸å…³å†…å®¹")

        session.close()
        print_status("è¯­æ–‡æ•™ææœç´¢æµ‹è¯•å®Œæˆ", "âœ…")
        return True

    except Exception as e:
        print_status(f"è¯­æ–‡æ•™ææœç´¢æµ‹è¯•å¤±è´¥: {e}", "âŒ")
        return False


def test_lesson_structure():
    """æµ‹è¯•è¯¾æ–‡ç»“æ„åŒ–ä¿¡æ¯"""
    print_status("æµ‹è¯•è¯¾æ–‡ç»“æ„åŒ–ä¿¡æ¯", "ğŸ“–")

    try:
        SessionLocal = sessionmaker(bind=engine)
        session = SessionLocal()

        # è·å–æ‰€æœ‰è¯­æ–‡æ•™æå†…å®¹
        chunks = session.query(TextbookChunk).filter(
            TextbookChunk.source_file.like('%è¯­æ–‡%')
        ).all()

        print(f"ğŸ“Š è¯­æ–‡æ•™ææ€»ç‰‡æ®µæ•°: {len(chunks)}")

        # ç»Ÿè®¡å•å…ƒå’Œè¯¾æ–‡åˆ†å¸ƒ
        units = {}
        lessons = {}

        for chunk in chunks:
            metadata = chunk.metadata_json or {}
            unit_title = metadata.get('unit_title', 'æœªçŸ¥å•å…ƒ')
            lesson_title = metadata.get('lesson_title', 'æœªçŸ¥è¯¾æ–‡')

            if unit_title not in units:
                units[unit_title] = 0
            units[unit_title] += 1

            if lesson_title not in lessons:
                lessons[lesson_title] = 0
            lessons[lesson_title] += 1

        print(f"\nğŸ“š å•å…ƒåˆ†å¸ƒ ({len(units)} ä¸ªå•å…ƒ):")
        for unit, count in sorted(units.items()):
            print(f"  {unit}: {count} ä¸ªç‰‡æ®µ")

        print(f"\nğŸ“– è¯¾æ–‡åˆ†å¸ƒ ({len(lessons)} ç¯‡è¯¾æ–‡):")
        for lesson, count in sorted(lessons.items()):
            if lesson != 'æœªçŸ¥è¯¾æ–‡':
                print(f"  {lesson}: {count} ä¸ªç‰‡æ®µ")

        # æ˜¾ç¤ºä¸€äº›è¯¦ç»†çš„è¯¾æ–‡ç¤ºä¾‹
        print(f"\nğŸ” è¯¾æ–‡å†…å®¹ç¤ºä¾‹:")
        sample_chunks = chunks[:3]
        for i, chunk in enumerate(sample_chunks):
            metadata = chunk.metadata_json or {}
            print(f"\n--- ç¤ºä¾‹ {i+1} ---")
            print(f"ğŸ“– è¯¾æ–‡: {metadata.get('lesson_title', 'æœªçŸ¥')}")
            print(f"ğŸ“š å•å…ƒ: {metadata.get('unit_title', 'æœªçŸ¥')}")
            print(f"ğŸ“„ é¡µç : {chunk.page_number}")
            print(f"â­ è´¨é‡è¯„åˆ†: {chunk.quality_score:.3f}")
            print(f"ğŸ“ å†…å®¹: {chunk.content}")

        session.close()
        print_status("è¯¾æ–‡ç»“æ„åŒ–ä¿¡æ¯æµ‹è¯•å®Œæˆ", "âœ…")
        return True

    except Exception as e:
        print_status(f"è¯¾æ–‡ç»“æ„åŒ–ä¿¡æ¯æµ‹è¯•å¤±è´¥: {e}", "âŒ")
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ¯ ä½œä¸šæ­å­ è¯­æ–‡æ•™æ RAG ç³»ç»Ÿ - ä¸“é¡¹æµ‹è¯•")
    print("=" * 60)

    tests = [
        ("è¯­æ–‡æ•™ææœç´¢", test_chinese_textbook_search),
        ("è¯¾æ–‡ç»“æ„åŒ–ä¿¡æ¯", test_lesson_structure)
    ]

    passed = 0
    total = len(tests)

    for name, test_func in tests:
        try:
            print(f"\nğŸ§ª è¿è¡Œæµ‹è¯•: {name}")
            if test_func():
                print(f"âœ… {name} - é€šè¿‡")
                passed += 1
            else:
                print(f"âŒ {name} - å¤±è´¥")
        except Exception as e:
            print(f"âŒ {name} - å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()

    print("\n" + "=" * 60)
    print(f"ğŸ“Š æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")

    if passed == total:
        print("ğŸ‰ è¯­æ–‡æ•™æRAGåŠŸèƒ½æµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")
        print("ğŸ’¡ è¯­æ–‡æ•™æçŸ¥è¯†åº“å·²ç»å¯ä»¥æ”¯æŒæ™ºèƒ½é—®ç­”")
        print("\nğŸš€ ä¸‹ä¸€æ­¥å»ºè®®:")
        print("  1. é›†æˆChainlitç•Œé¢è¿›è¡Œå­¦ç”Ÿäº¤äº’æµ‹è¯•")
        print("  2. æ·»åŠ é—®ç­”ç”ŸæˆåŠŸèƒ½")
        print("  3. å®ç°è¯¾æ–‡å†…å®¹çš„æ™ºèƒ½æ¨è")
        return 0
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é—®é¢˜")
        return 1


if __name__ == "__main__":
    sys.exit(main())