#!/usr/bin/env python3
"""
è¯­æ–‡æ•™æå‘é‡åŒ–å¤„ç†è„šæœ¬
Chinese Textbook Vectorization Script
"""

import sys
import os
from pathlib import Path
import hashlib
from datetime import datetime
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from dotenv import load_dotenv
load_dotenv()

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from homeworkpal.database.connection import engine, get_db
from homeworkpal.database.models import TextbookChunk
from homeworkpal.llm.siliconflow import create_siliconflow_client
from homeworkpal.document import (
    create_pdf_processor,
    create_pdf_splitter,
    create_chinese_text_processor
)
from sqlalchemy.orm import sessionmaker

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def print_status(message: str, status: str):
    """æ‰“å°çŠ¶æ€ä¿¡æ¯"""
    icons = {"âœ…": "âœ…", "âŒ": "âŒ", "âš ï¸": "âš ï¸", "ğŸ”§": "ğŸ”§", "ğŸ“š": "ğŸ“š", "ğŸ”": "ğŸ”", "ğŸ’¾": "ğŸ’¾"}
    print(f"{icons.get(status, 'â„¹ï¸')} {message}")


def process_chinese_textbook():
    """å¤„ç†è¯­æ–‡æ•™æPDFå¹¶ç”Ÿæˆå‘é‡åµŒå…¥"""
    pdf_path = "data/textbooks/è¯­æ–‡ä¸‰ä¸Š.pdf"

    print_status("å¼€å§‹å¤„ç†è¯­æ–‡æ•™æå‘é‡åŒ–", "ğŸ“š")
    print("=" * 60)

    try:
        # 1. åˆ›å»ºå¤„ç†ç»„ä»¶
        print_status("åˆ›å»ºå¤„ç†å™¨ç»„ä»¶", "ğŸ”§")
        processor = create_pdf_processor(subject='è¯­æ–‡')
        splitter = create_pdf_splitter(subject='è¯­æ–‡')
        embedding_client = create_siliconflow_client()
        text_processor = create_chinese_text_processor(embedding_client)

        print(f"âœ… æ‰€æœ‰ç»„ä»¶åˆ›å»ºæˆåŠŸ")

        # 2. å¤„ç†PDFï¼ˆåªå¤„ç†å‰3é¡µç”¨äºæµ‹è¯•ï¼‰
        print_status("å¤„ç†PDFæ–‡æ¡£", "ğŸ“„")
        pdf_result = processor.extract_text_from_pdf(pdf_path)

        # é™åˆ¶å¤„ç†é¡µæ•°
        test_pages = pdf_result['pages'][:3]
        test_result = pdf_result.copy()
        test_result['pages'] = test_pages

        print(f"âœ… PDFå¤„ç†å®Œæˆ: {len(test_pages)} é¡µ")

        # 3. åˆ†å‰²æ–‡æ¡£
        print_status("åˆ†å‰²æ–‡æ¡£å†…å®¹", "âœ‚ï¸")
        chunks = splitter.split_pdf_content(test_result)
        print(f"âœ… ç”Ÿæˆ {len(chunks)} ä¸ªæ–‡æ¡£ç‰‡æ®µ")

        # 4. å‡†å¤‡æ–‡æœ¬å†…å®¹
        text_contents = [chunk['content'] for chunk in chunks]

        # æ˜¾ç¤ºç‰‡æ®µä¿¡æ¯
        for i, chunk in enumerate(chunks[:3]):
            print(f"ç‰‡æ®µ {i+1}: ç±»å‹={chunk.get('content_type', 'æœªçŸ¥')}, é•¿åº¦={chunk.get('text_length', 0)}")

        # 5. è´¨é‡è¯„ä¼°å’Œé¢„å¤„ç†
        print_status("è¯„ä¼°æ–‡æœ¬è´¨é‡", "ğŸ”")
        for i, content in enumerate(text_contents[:3]):
            quality = text_processor.assess_embedding_quality(content)
            processed = text_processor.preprocess_chinese_text_for_embedding(content)
            print(f"  ç‰‡æ®µ {i+1}: è¯„åˆ†={quality['score']:.2f}, å¤„ç†åé•¿åº¦={len(processed)}")

        # 6. æ‰¹é‡å‘é‡åŒ–
        print_status("å¼€å§‹æ‰¹é‡å‘é‡åŒ–", "âš¡")
        start_time = datetime.now()

        embeddings, quality_results = text_processor.batch_vectorize_with_quality_control(
            text_contents,
            batch_size=2,  # å°æ‰¹æ¬¡æµ‹è¯•
            max_retries=2
        )

        end_time = datetime.now()
        processing_time = (end_time - start_time).total_seconds()

        print(f"âœ… å‘é‡åŒ–å®Œæˆ:")
        print(f"  - å¤„ç†æ—¶é—´: {processing_time:.1f}ç§’")
        print(f"  - å‘é‡æ•°é‡: {len(embeddings)}")
        print(f"  - å‘é‡ç»´åº¦: {len(embeddings[0]) if embeddings else 0}")

        # 7. ä¿å­˜åˆ°æ•°æ®åº“
        print_status("ä¿å­˜åˆ°æ•°æ®åº“", "ğŸ’¾")
        save_chunks_to_database(chunks, embeddings, test_result)

        print_status("è¯­æ–‡æ•™æå‘é‡åŒ–å¤„ç†å®Œæˆ!", "ğŸ‰")
        return True

    except Exception as e:
        print_status(f"å¤„ç†å¤±è´¥: {e}", "âŒ")
        import traceback
        traceback.print_exc()
        return False


def save_chunks_to_database(chunks, embeddings, pdf_result):
    """ä¿å­˜æ–‡æ¡£ç‰‡æ®µåˆ°æ•°æ®åº“"""
    SessionLocal = sessionmaker(bind=engine)
    session = SessionLocal()

    try:
        saved_count = 0

        for i, chunk in enumerate(chunks):
            # ç”Ÿæˆå†…å®¹å“ˆå¸Œ
            content_hash = hashlib.md5(chunk['content'].encode('utf-8')).hexdigest()

            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            existing = session.query(TextbookChunk).filter_by(
                content_hash=content_hash
            ).first()

            if existing:
                print(f"è·³è¿‡é‡å¤å†…å®¹: {content_hash[:8]}...")
                continue

            # åˆ›å»ºæ•°æ®åº“è®°å½•
            db_chunk = TextbookChunk(
                content=chunk['content'],
                embedding=embeddings[i] if i < len(embeddings) else [0.0] * 1024,
                content_hash=content_hash,
                metadata_json={
                    'pdf_file': pdf_result['file_name'],
                    'subject': pdf_result['education_metadata']['subject'],
                    'grade': pdf_result['education_metadata']['grade'],
                    'content_type': chunk.get('content_type', 'æœªçŸ¥'),
                    'page_number': chunk['page_number'],
                    'quality_score': chunk['quality_score']
                },
                source_file=pdf_result['file_path'],
                chunk_index=chunk['chunk_index'],
                page_number=chunk['page_number'],
                quality_score=chunk['quality_score']
            )

            session.add(db_chunk)
            saved_count += 1

        session.commit()
        print(f"âœ… ä¿å­˜äº† {saved_count} ä¸ªæ–°ç‰‡æ®µåˆ°æ•°æ®åº“")

    except Exception as e:
        session.rollback()
        raise e
    finally:
        session.close()


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ è¯­æ–‡æ•™æå‘é‡åŒ–å¤„ç†è„šæœ¬")
    print("=" * 60)

    # æ£€æŸ¥ç¯å¢ƒ
    if not Path("data/textbooks/è¯­æ–‡ä¸‰ä¸Š.pdf").exists():
        print_status("PDFæ–‡ä»¶ä¸å­˜åœ¨", "âŒ")
        return False

    if not os.getenv("SILICONFLOW_API_KEY"):
        print_status("æœªè®¾ç½®SILICONFLOW_API_KEY", "âŒ")
        return False

    # æ‰§è¡Œå¤„ç†
    return process_chinese_textbook()


if __name__ == "__main__":
    main()