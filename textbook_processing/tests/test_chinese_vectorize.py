#!/usr/bin/env python3
"""
æµ‹è¯•è¯­æ–‡æ•™æå‘é‡åŒ–
Test Chinese Textbook Vectorization
"""

import sys
from pathlib import Path
import hashlib

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from dotenv import load_dotenv
load_dotenv()

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from homeworkpal.document import create_pdf_processor, create_pdf_splitter


def test_chinese_processing():
    """æµ‹è¯•è¯­æ–‡æ•™æå¤„ç†"""
    print("ğŸ”§ æµ‹è¯•è¯­æ–‡æ•™æå¤„ç†")
    print("=" * 40)

    # 1. æµ‹è¯•PDFå¤„ç†
    processor = create_pdf_processor(subject='è¯­æ–‡')
    print(f"âœ… å¤„ç†å™¨åˆ›å»º: {type(processor).__name__}")

    pdf_path = "data/textbooks/è¯­æ–‡ä¸‰ä¸Š.pdf"
    if not Path(pdf_path).exists():
        print(f"âŒ PDFæ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")
        return False

    try:
        # å¤„ç†å‰2é¡µ
        result = processor.extract_text_from_pdf(pdf_path)
        test_pages = result['pages'][:2]

        print(f"âœ… PDFå¤„ç†æˆåŠŸ:")
        print(f"  - æ–‡ä»¶å: {result['file_name']}")
        print(f"  - å­¦ç§‘: {result['education_metadata']['subject']}")
        print(f"  - å¹´çº§: {result['education_metadata']['grade']}")
        print(f"  - æµ‹è¯•é¡µæ•°: {len(test_pages)}")

        # 2. æµ‹è¯•åˆ†å‰²
        splitter = create_pdf_splitter(subject='è¯­æ–‡')
        print(f"âœ… åˆ†å‰²å™¨åˆ›å»º: {type(splitter).__name__}")

        test_result = result.copy()
        test_result['pages'] = test_pages
        chunks = splitter.split_pdf_content(test_result)

        print(f"âœ… åˆ†å‰²å®Œæˆ: {len(chunks)} ä¸ªç‰‡æ®µ")

        # æ˜¾ç¤ºç‰‡æ®µä¿¡æ¯
        for i, chunk in enumerate(chunks[:3]):
            content_hash = hashlib.md5(chunk['content'].encode('utf-8')).hexdigest()
            print(f"\\n--- ç‰‡æ®µ {i+1} ---")
            print(f"  ID: {chunk['id']}")
            print(f"  ç±»å‹: {chunk.get('content_type', 'æœªçŸ¥')}")
            print(f"  é¡µé¢: {chunk['page_number']}")
            print(f"  é•¿åº¦: {chunk['text_length']} å­—ç¬¦")
            print(f"  è´¨é‡: {chunk['quality_score']:.2f}")
            print(f"  å“ˆå¸Œ: {content_hash[:8]}...")
            print(f"  é¢„è§ˆ: {chunk['content'][:100]}...")

        print(f"\\nâœ… å¤„ç†æµ‹è¯•æˆåŠŸå®Œæˆ!")
        return True

    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»å‡½æ•°"""
    return test_chinese_processing()


if __name__ == "__main__":
    success = main()
    if success:
        print("\\nğŸ‰ è¯­æ–‡æ•™æå¤„ç†æµ‹è¯•æˆåŠŸ!")
    else:
        print("\\nâŒ è¯­æ–‡æ•™æå¤„ç†æµ‹è¯•å¤±è´¥!")